```{r setup_results, include=FALSE}
knitr::opts_knit$set(kable.force.latex = TRUE)
knitr::opts_chunk$set(fig.pos = 'H')
knitr::opts_chunk$set(fig.align = "center")

require(ggplot2)
require(dplyr)
require(resample)
require(cowplot)
require(gridExtra)
```

```{r datasets, cache=TRUE}
# Constants
NUM_RESAMPLES <- 1000
COLOR_BLIND_PALETTE <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")

# Reading data;
t1 <- read.csv("../data/1core/throughput.csv") %>%
  select(-ts) %>%
  filter(throughput != 0.0) %>%
  na.omit()

t2 <- read.csv("../data/2cores/throughput.csv") %>%
  select(-ts) %>%
  filter(throughput != 0.0) %>%
  na.omit()

t4 <- read.csv("../data/4cores/throughput.csv") %>%
  select(-ts) %>%
  filter(throughput != 0.0) %>%
  na.omit()

# Indirect Factors
## Throughput per VCPU
t1["avgt"] <- t1$throughput
t2["avgt"] <- t2$throughput/2
t4["avgt"] <- t4$throughput/4


# Auxiliary functions.
ci.data <- function(currLoad, data, col) {
  d <- filter(data, load == currLoad)
  b <- bootstrap(d[[col]], mean, R = NUM_RESAMPLES)
  ci <- CI.percentile(b, probs = c(.005, .995))
  return (data.frame(load=currLoad, mean=mean(ci), lower=ci[1], upper=ci[2]))
}

ci.data.frame <- function(data, col) {
  loadList <- data$load %>% unique() %>% sort()
  d <- data.frame(load = c(), upper = c(), mean = c(), lower = c())
  for (currLoad in loadList) {
    d <- rbind(d, ci.data(currLoad, data, col))
  }
  d <- arrange(d, desc(mean))
  return(d)
}

perf.plot <- function(data, col, yTitle) {
 ggplot(ci.data.frame(data, col), aes(x = load, y = mean)) +
  geom_errorbar(aes(ymin = lower, ymax = upper), width=.2, size=0.5, color = "darkblue")+
  geom_point(size = 1, color = "black") +
  geom_line(alpha=0.5, color = "darkgrey") +
  geom_bar(stat="identity", fill="white", colour="darkgrey", alpha=0.1) +
  ylab(yTitle) +
  xlab("Load (Req/Sec)") +
  scale_color_manual(values = COLOR_BLIND_PALETTE)
}
```
## Exp1: Running the HTTP Server in a 1-vCPU VM

The summary of the result set for the experiment *Exp1* is shown bellow:

```{r, t1_sum, echo=FALSE}
knitr::kable(summary(t1), caption = "Exp1 results summary.", longtable = FALSE)
```

A quick look at Table 1 tells us that the maximum load impressed on the server was 1500 queries per second (QPS). It also shows a server throughput peak of 1201.9 QPS. For this particular experiment, *throughput* and *avgt* are equal. This is because the virtual machine used to run the server has only one vCPU.

Throughput mean and median are pretty close, which indicates a peak closer to the center of the distribution. Drilling down into the experiments results, we show bellow  distribution of load versus throughput:

```{r t1_plot,  echo=FALSE, fig.align="center", fig.pos="H", fig.height=2, fig.width=3.5, ig.cap="Graphical display of the throughput handled by the server given a certain load (1 vCPU).", cache=TRUE}
perf.plot(t1, "throughput", "T (Req/Sec)")

ci.t1 <- ci.data.frame(t1, "throughput")

max.troughput.t1 <- ci.t1 %>% filter(mean == max(ci.t1$mean))
min.troughput.t1 <- ci.t1 %>% filter(mean == min(ci.t1$mean))
```

The error bars indicate a 95\% confident interval for the mean. The confidence interval was computed using Bootstrap re-sampling (simulation-based statistical estimation technique [@efron1994introduction]) with 10,000 trials because distributions were non-normal.

The plot shows a pretty much linear server throughput increase until `r round(min.troughput.t1$mean, 2)`, at which point it is being impressed  a load of `r min.troughput.t1$load` QPS. This is called saturation point and at this point the server is at full capacity.

After this point the server is overloaded and as more load is added to the system (simulating clients in a e-commerce website, for instance), the only effect is that the accept queue at the server will grow in size [@Banga:1999:MCW:598682.598725]. At some point requests are going to start to timeout and fail, leading to a decrease in throughput. Besides that, the runtime itself starts needed more bookkeeping, for instance, more stop-of-the-world pauses [@995163] happen and more CPU is consumed by the garbage collector.

We believe all these reasons could explain:

1. Steep decrease in the throughput: there is more and more competition for the only vCPU available
1. Increase in the size of the error bars: due to the unpredictability nature of the GC and other runtime components leads to a great variance in the system performance

We better understand how these factors correlate is part our future plans. Finally, at the very end (`r min.troughput.t1$load` load) we have a practically inoperative server, successfully answering `r round(min.troughput.t1$mean, 2)` QPS.

## Exp2: Running the HTTP Server in a 2-vCPUs VM

At this experiment, we have the HTTP server running in a virtual machine with 2 vCPUs. As there is nothing new in the data summary, lets jump straight to the expert throughput distribution plot, which is shown bellow:

```{r t2_plot,  echo=FALSE, fig.align="center", fig.pos="H", fig.height=2, fig.width=3.5, fig.cap="Graphical display of the throughput handled by the server given a certain load (2 vCPUs).", cache=TRUE}
perf.plot(t2, "throughput", "T (Req/Sec)")

ci.t2 <- ci.data.frame(t2, "throughput")
ci.t2.avgt <- ci.data.frame(t2, "avgt")
```
```{r echo=FALSE, cache=TRUE}
max.troughput.t2 <- ci.t2 %>% filter(mean == max(ci.t2$mean))
min.troughput.t2 <- ci.t2 %>% filter(load == 3000)
```

Again, the error bars indicate a 95\% confident interval for the mean. The confidence interval was computed using Bootstrap re-sampling (simulation-based statistical estimation technique [@efron1994introduction]) with 10,000 trials because distributions were non-normal.

First thing to notice is the double size of vertical axis when compared to *Exp1*. At a first glance, this seems expected: we doubled the server capacity, we expect the throughput to double (hold tight, you will see that this is not always true). The shape of the curve is also very similar to Figure $\ref{fig:t1_plot}$ and we believe the steep decrease/size of the error bars are due to the same reasons described in *Exp1*.

Another important point is the server reaches saturation at `r max.troughput.t2$load` QPS, handling `r round(max.troughput.t2$mean, 2)` requests per second on average. In other words, doubling the amount of resources leads to the almost linear speedup (precisely  `r round(max.troughput.t2$mean/max.troughput.t1$mean, 2)`). On the other extreme, at the right-hand side of the chart we see a stabilization trend around `r round(min.troughput.t2$mean, 0)` QPS. We need more experiments to increase our confidence, but it seems that adding the extra core increases the chance to the system to keep operating - even if in a very inefficient way.

Finally, bellow we compare average throughput per core observed in *Exp1* and *Exp2* :

```{r t1t2_plot,  echo=FALSE, fig.align="center", fig.pos="H",fig.height=2, fig.width=3.5, fig.cap="Comparing Exp1 and Exp2 average throughput (avgT)", cache=TRUE}
 ggplot() +
  geom_point(data=ci.t1, aes(x=load, y=mean, color="1 vCPU"), size = 2) +
  geom_line(data=ci.t1, aes(x=load, y=mean, color="1 vCPU"), alpha=0.2, color = "darkgrey") +
  geom_errorbar(data=ci.t1, aes(x=load, ymin = lower, ymax = upper, color="1 vCPU"), width=.2, size=0.5)+
  geom_point(data=ci.t2.avgt, aes(x=load/2, y=mean, color="2 vCPUs"), size = 2) +
  geom_line(data=ci.t2.avgt, aes(x=load/2, y=mean, color="2 vCPUs"), alpha=0.1) +
  geom_errorbar(data=ci.t2.avgt, aes(x=load/2, ymin = lower, ymax = upper, color="2 vCPUs"), width=.2, size=0.5)+
  ylab("avgT (Req/Sec)") +
  xlab("Load (Req/Sec)") +
  scale_color_manual(values = COLOR_BLIND_PALETTE) +
  guides(colour=guide_legend(title=NULL))
```

To be in pair with the averaged throughput, we averaged the QPS as well. As one can see the, there is no statistical evidence of difference in the curves, which confirms our prior analysis.

## Exp4: Running the HTTP Server in a 4-vCPUs VM

In this case we have the HTTP server running in a virtual machine with 4 vCPUs. The summary of the result set for the experiment is shown bellow:

```{r, t4_sum, echo=FALSE}
knitr::kable(summary(t4), caption = "Exp4 results summary.", longtable= FALSE)
```

To our surprise, the maximum throughput handled by the server is only `r round(max(t4$throughput), 2)` QPS. Median and mean have close values and those are close to the ones in *Exp2* (or twice as big as *Exp1*). The next step is to look at the distribution chart, which is shown bellow:

```{r t4_plot,  fig.align="center", fig.pos="H", fig.height=2, fig.width=3.5, fig.cap="Graphical display of the throughput handled by the server given a certain load (4 vCPUs).", cache=TRUE}
perf.plot(t4, "throughput", "T (Req/Sec)")

ci.t4 <- ci.data.frame(t4, "throughput")
ci.t4.avgt <- ci.data.frame(t4, "avgt")
```
```{r echo=FALSE, cache=TRUE}
max.troughput.t4 <- ci.t4 %>% filter(mean == max(ci.t4$mean))
```

Again, the error bars indicate a 95\% confident interval for the mean. The confidence interval was computed using Bootstrap re-sampling (simulation-based statistical estimation technique [@efron1994introduction]) with 10,000 trials because distributions were non-normal.

The first thing that calls out our attention is the bi-modal shape of the distribution. More importantly, looking at the confidence intervals, we could say this with quite high statistical confidence. That could be many reasons for that and investigating those reasons is out of the scope of this study.

As the distribution is bi-modal and we do not see a clear decrease trend, we can not tell what is the server saturation point based on these results. In any case, the maximum throughput handled by the server is `r round(max.troughput.t4$mean, 2)` QPS, which happened `r max.troughput.t4$load` QPS load. Finally, to verify how efficient the usage of each core was on average, we show bellow $avgT$ chart for *Exp4* and *Exp1* results:

```{r t4avgt_plot,  fig.align="center", fig.pos="H", fig.height=2, fig.width=3.5, fig.cap="Comparing Exp1 and Exp4 average throughput", cache=TRUE}
 ggplot() +
  geom_point(data=ci.t1, aes(x=load, y=mean, color="1 vCPU"), size = 2) +
  geom_line(data=ci.t1, aes(x=load, y=mean, color="1 vCPU"), alpha=0.2, color = "darkgrey") +
  geom_errorbar(data=ci.t1, aes(x=load, ymin = lower, ymax = upper, color="1 vCPU"), width=.2, size=0.5)+
  geom_point(data=ci.t4.avgt, aes(x=load/2, y=mean, color="4 vCPUs"), size = 2) +
  geom_line(data=ci.t4.avgt, aes(x=load/2, y=mean, color="4 vCPUs"), alpha=0.1) +
  geom_errorbar(data=ci.t4.avgt, aes(x=load/2, ymin = lower, ymax = upper, color="4 vCPUs"), width=.2, size=0.5)+
  ylab("avgT (Req/Sec)") +
  xlab("Load (Req/Sec)") +
  scale_color_manual(values = COLOR_BLIND_PALETTE) +
  guides(colour=guide_legend(title=NULL))
```

```{r t2t4diffpvalue, echo=FALSE, cache=TRUE}
boot_diff <- bootstrap2(
  data=t4$avgt,
  data2=t2$avgt,
  statistic = mean,
  R = NUM_RESAMPLES)
ci.t2.t4.diff <- CI.percentile(boot_diff, probs = c(.005, .995))
```