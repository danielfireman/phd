# Methodology {#sec:met} 

On the one hand performance has a direct and important impact on business
objectives. On the other hand, every service has a unique set of
requirements and often execute in resources which vary in vastly different
ways. As an attempt to provide adequate performance out of the box for the
broadest range of application-execution resource pairs, JVM
(Java$\textsuperscript{TM}$ Virtual Machine) comes  with a set of default
parameters.

Our goal with this paper is to assess how the overhead that is
not application-specific (i.e. HTTP request handling framework, JVM
maintenance  tasks) impacts an asynchronous event-driven HTTP server that
runs under high utilization.

In other words, we would like to find which VM configuration leads to the
greatest saturation point[^1]. To do so, clients [^2] collect one piece of data: the number of requests processed per second (throughput, $T$). Based on this information, we can calculate an indirect metric:

[^1]: The saturation point tells that the service has reached its maximum capacity for the specific version (code), configuration and environment [@perfTestingWebSphere].

[^2]: Code can be found at https://git.io/v6lCf.

$$avgT(n_{vCPUs}) = \frac{T}{n_{vCPUs}}$$

Where $avgT(n_{VCPUs})$ is the average throughput per available virtual CPU (VCPU), $n_{VCPUs}$ is the number of vCPUs available for execution and $T$ is the throughput. Based on the latter, we can formally express the experimental hypotheses:

* $H_{0}$: The maximum throughput increases linearly with the increasing number of vCPUs allocated to run a highly-loaded single-endpoint REST service on an asynchronous event-driven Java™ HTTP server configured with default JVM flags. Or more formally:

$$max(avgT(k)) \approx max(avgT(k+1)),\, \forall k > 0$$

* $H_{1}$: The maximum throughput does not increase linearly with the increasing number of vCPUs 
allocated to run a highly-loaded single-endpoint REST service on an asynchronous event-driven 
Java $\textsuperscript{TM}$ HTTP server configured with default JVM flags. Or more formally:

$$\exists k>0, \, max(avgT(k))\,\ne\, max(avgT(k+1))$$

## Experimental Setup

To achieve the experiment goal, the Java HTTP server business logic overhead was trimmed down. The request handling internals was handled by i) Netty [@Maurer:2015:NA:2838857], anasynchronous event-driven network application
framework and ii) Jooby [@jooby], a micro web framework for Java, both without
any custom parameters or configuration. The request handling logic was negligible, as well as the request and response payloads[^3]. The Java HotSpot Virtual Machine was used in all experiments.

[^3]: Code can be found at https://git.io/v64D7.

The load was impressed on the server using the monotonically increasing 
step-function[@stepFun] described bellow. At every 10 seconds, the load was
increased by:

$$load(i) = i \cdot n_{vCPUs} \cdot 50, \, \forall x,y,\,\, x \leq y \implies load(x) \leq load(y)$$

Where $i$ is the index of the current step. At the beginning of every experiment the server received a load of $n_{vCPUs} * 50$ QPS. This warm up phase aims at
mitigate the impact of Java's Just In Time (JIT) compiler and other internal JVM
mechanisms.

We conducted a series of experiments varying the number of CPUs available
at the virtual machine executing the server. Experiments were conducted using 1,
2 and 4 vCPUs (named *Exp1*, *Exp2*, *Exp4*). Each experiment was repeated 10
times. Table \ref{tab:expsetup} presents details of each experiment
configuration.

\begin{table}[H]
\centering
\begin{tabular}{lcccc}
  Name & \#vCPUs & RAM(GB) & Disk(GB) \\ 
  \hline\hline
  Exp1 & 1 & 0.50 & 10.00 \rule{0pt}{3ex} \\ 
  Exp2 & 2 & 4.00 & 60.00 \\ 
  Exp4 & 4 & 8.00 & 90.00 \\ 
\end{tabular}
\caption{Experiment setup.} 
\label{tab:expsetup}
\end{table}

As there is a negligible amount of serial work done at request handling (business
logic), one trying to predict the server performance based on either 
Amdahl’s Law (using $\sigma \approx 0$), Gustafson’s Law (using $\sigma'(1) \approx 0$)
or Super-Serial Model (using $\sigma \approx 0$ and $\gamma \approx 0$) would
expect a speedup very close to linear[@DBLP:conf/cmg/WilliamsS04].
In other words, the degree of parallelism in the application is such that it could
make (almost) full use of the additional resources provided by scaling.

To our surprise, experimental results refute that hypothesis. These results are
presented at next Section.

<!--Each client output the number of requests successfully attended by the
server per second during each step (throughput). The data was collected and processed to generate consolidated view of the troughput[^2].

[^2]: Code can be found at https://git.io/v6lCf.

The consolidated view has one entry per step, each entry contains:

* Load: number of requests per second sent to the server during the step
* Throughput: number requests successfully processed by the server per second
during the step.

Lastly the column $avgt$ is added. This column represents $avgT(n_{vCPUs})$ and it is calculated by dividing the throughput of each row by the number of available vCPUs available at the VM used to the run the HTTP server. The code used to calculate this and all other indirect metrics can be found [here](https://github.com./danielfireman/phd). -->
